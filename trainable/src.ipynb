{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainable GFRFT: Transform Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Iterable\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch_gfrft import EigvalSortStrategy\n",
    "from torch_gfrft.gfrft import GFRFT\n",
    "from torch_gfrft.gft import GFT\n",
    "from torch_gfrft.layer import GFRFTLayer\n",
    "\n",
    "SEED = 0\n",
    "NODE_DIM = 0\n",
    "NUM_NODES = 100\n",
    "TIME_LENGTH = 200\n",
    "EIGVAL_SORT_STRATEGY = EigvalSortStrategy.TOTAL_VARIATION\n",
    "SYMMETRIC = False\n",
    "SELF_LOOPS = False\n",
    "\n",
    "if th.cuda.is_available():\n",
    "    DEVICE = th.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = th.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    th.use_deterministic_algorithms(True)\n",
    "    th.manual_seed(seed)\n",
    "    if th.cuda.is_available():\n",
    "        th.backends.cudnn.benchmark = False\n",
    "        th.cuda.manual_seed_all(seed)\n",
    "        os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Random Graph and Corresponding GFRFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adjecency(\n",
    "    num_nodes: int,\n",
    "    device: th.device,\n",
    "    symmetric: bool = False,\n",
    "    self_loops: bool = False,\n",
    "):\n",
    "    A = th.rand(num_nodes, num_nodes, device=device)\n",
    "    if symmetric:\n",
    "        A = 0.5 * (A + A.T)\n",
    "    if not self_loops:\n",
    "        A = A - th.diag(th.diag(A))\n",
    "    return A\n",
    "\n",
    "\n",
    "adjacency = generate_adjecency(NUM_NODES, DEVICE, SYMMETRIC, SELF_LOOPS)\n",
    "gft = GFT(adjacency, EIGVAL_SORT_STRATEGY)\n",
    "gfrft = GFRFT(gft.gft_mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NODE_DIM == 0:\n",
    "    X = th.rand(NUM_NODES, TIME_LENGTH, device=DEVICE)\n",
    "elif NODE_DIM == 1:\n",
    "    X = th.rand(TIME_LENGTH, NUM_NODES, device=DEVICE)\n",
    "else:\n",
    "    raise ValueError(\"NODE_DIM must be 0 or 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "Transform the original signals using the GFRFT with fractional order `original_order`. By using the transformed signals as ground truth and MSE loss function, learn the multi-GFRFT layer network's fractional orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): GFRFT(order=0.0, size=100, dim=0)\n",
      "  (1): GFRFT(order=1.0, size=100, dim=0)\n",
      ")\n",
      "original order: 0.3500\n",
      "learning rate: 0.0005\n",
      "initial orders: a1 =  0.0000 | a2 =  1.0000 | sum =  1.0000\n",
      "-----------------------------------------------------------\n",
      "Epoch  500 | Loss   9.8519 | a1 = -0.1549 | a2 =  0.8451 | sum =  0.6901\n",
      "Epoch 1000 | Loss   0.9936 | a1 = -0.3138 | a2 =  0.6862 | sum =  0.3724\n",
      "Epoch 1500 | Loss   0.0093 | a1 = -0.3251 | a2 =  0.6749 | sum =  0.3498\n",
      "Epoch 2000 | Loss   0.0098 | a1 = -0.3249 | a2 =  0.6751 | sum =  0.3502\n",
      "-----------------------------------------------------------\n",
      "final orders: a1 = -0.3250 | a2 =  0.6750\n",
      "original order: 0.3500, final order sum: 0.3501\n"
     ]
    }
   ],
   "source": [
    "def mse_loss(predictions: th.Tensor, targets: th.Tensor) -> th.Tensor:\n",
    "    return th.norm(predictions - targets, p=\"fro\", dim=0).mean()\n",
    "\n",
    "\n",
    "def get_order_info(\n",
    "    model: nn.Sequential, show_sum: bool = False, sep: str = \" | \"\n",
    ") -> str:\n",
    "    orders = [layer.order.item() for layer in model]\n",
    "    info_str = sep.join(f\"a{i + 1} = {order: >7.4f}\" for i, order in enumerate(orders))\n",
    "    if show_sum:\n",
    "        info_str += f\"{sep}sum = {sum(orders): >7.4f}\"\n",
    "    return info_str\n",
    "\n",
    "\n",
    "def experiment(\n",
    "    gfrft: GFRFT,\n",
    "    original_signals: th.Tensor,\n",
    "    original_order: float,\n",
    "    initial_orders: Iterable[float],\n",
    "    *,\n",
    "    dim: int = -1,\n",
    "    lr: float = 5e-4,\n",
    "    epochs: int = 1000,\n",
    "    display_epochs: Iterable[int] | None = None,\n",
    "    show_sum_during_training: bool = False,\n",
    "):\n",
    "    if display_epochs is None:\n",
    "        display_epochs = (e for e in range(0, epochs, 100))\n",
    "    display_epochs = set(display_epochs)\n",
    "    transformed_signals = gfrft.gfrft(original_signals, original_order, dim=dim)\n",
    "    model = nn.Sequential(\n",
    "        *[GFRFTLayer(gfrft, order, dim=dim) for order in initial_orders]\n",
    "    )\n",
    "    print(model)\n",
    "    print(f\"original order: {original_order:.4f}\")\n",
    "    print(f\"learning rate: {lr}\")\n",
    "    optim = th.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    start_str = (\n",
    "        f\"initial orders: {get_order_info(model, show_sum=show_sum_during_training)}\"\n",
    "    )\n",
    "    print(start_str)\n",
    "    print(\"-\" * len(start_str))\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        optim.zero_grad()\n",
    "        output = mse_loss(model(original_signals), transformed_signals)\n",
    "        if epoch in display_epochs:\n",
    "            info = get_order_info(model, show_sum=show_sum_during_training)\n",
    "            print(f\"Epoch {epoch:4d} | Loss {output.item(): >8.4f} | {info}\")\n",
    "        output.backward()\n",
    "        optim.step()\n",
    "    print(\"-\" * len(start_str))\n",
    "    print(f\"final orders: {get_order_info(model)}\")\n",
    "    final_sum = sum(layer.order.item() for layer in model)\n",
    "    print(f\"original order: {original_order:.4f}, final order sum: {final_sum:.4f}\")\n",
    "\n",
    "experiment(\n",
    "    gfrft=gfrft,\n",
    "    original_signals=X,\n",
    "    original_order=0.35,\n",
    "    initial_orders=[0.0, 1.0],\n",
    "    lr=5e-4,\n",
    "    dim=NODE_DIM,\n",
    "    epochs=2000,\n",
    "    display_epochs=[0, 500, 1000, 1500, 2000],\n",
    "    show_sum_during_training=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
