{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainable GFRFT: Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Iterable, List\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from filtering import GFRFTFilterLayer, Real\n",
    "from torch_gfrft import EigvalSortStrategy\n",
    "from torch_gfrft.gfrft import GFRFT\n",
    "from torch_gfrft.gft import GFT\n",
    "from utils import (\n",
    "    add_gaussian_noise,\n",
    "    init_knn_from_mat,\n",
    "    mse_loss,\n",
    "    seed_everything,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "NODE_DIM = 0\n",
    "NUM_NODES = 100\n",
    "TIME_LENGTH = 200\n",
    "ORIGINAL_ORDER = 0.35\n",
    "LEARNING_RATE = 5e-4\n",
    "EPOCHS = 2000\n",
    "EIGVAL_SORT_STRATEGY = EigvalSortStrategy.TOTAL_VARIATION\n",
    "SYMMETRIC = False\n",
    "SELF_LOOPS = False\n",
    "DEVICE = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "KNN_COUNT = 10\n",
    "KNN_SIGMA = None\n",
    "MAX_NODE_COUNT = 100\n",
    "MAX_TIME_LENGTH = 120\n",
    "GRAPH_VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Real-World Data and Generate Graph with Joint Time-Vertex Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "datasets_path = Path.cwd().parent.joinpath(\"data\", \"tv-graph-datasets\").absolute()\n",
    "curr_dataset_path = datasets_path.joinpath(\"sea-surface-temperature.mat\")\n",
    "_, adjacency, jtv_signal = init_knn_from_mat(\n",
    "    curr_dataset_path,\n",
    "    knn_count=KNN_COUNT,\n",
    "    knn_sigma=KNN_SIGMA,\n",
    "    max_node_count=MAX_NODE_COUNT,\n",
    "    max_time_length=MAX_TIME_LENGTH,\n",
    "    device=DEVICE,\n",
    "    verbose=GRAPH_VERBOSE,\n",
    ")\n",
    "gft = GFT(adjacency, EIGVAL_SORT_STRATEGY)\n",
    "gfrft = GFRFT(gft.gft_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    gfrft: GFRFT,\n",
    "    original_signals: th.Tensor,\n",
    "    initial_orders: List[float],\n",
    "    cutoff_counts: List[int],\n",
    "    noise_sigma: float,\n",
    "    *,\n",
    "    noise_mean: float = 0.0,\n",
    "    dim: int = -1,\n",
    "    lr: float = 5e-4,\n",
    "    epochs: int = 1000,\n",
    "    display_epochs: Iterable[int] | None = None,\n",
    "    seed: int = 0,\n",
    "    trainable_transform: bool = True,\n",
    "    trainable_filter: bool = False,\n",
    ") -> nn.Module:\n",
    "    if len(initial_orders) != len(cutoff_counts):\n",
    "        raise ValueError(\"initial_orders and cutoff_counts must have the same length\")\n",
    "    if display_epochs is None:\n",
    "        display_epochs = (e for e in range(0, epochs, 100))\n",
    "    display_epochs = set(display_epochs)\n",
    "\n",
    "    seed_everything(seed)\n",
    "    noisy_signals = add_gaussian_noise(original_signals, noise_sigma, noise_mean)\n",
    "    filters = [\n",
    "        GFRFTFilterLayer(\n",
    "            gfrft,\n",
    "            cutoff,\n",
    "            order,\n",
    "            trainable_transform=trainable_transform,\n",
    "            trainable_filter=trainable_filter,\n",
    "        )\n",
    "        for order, cutoff in zip(initial_orders, cutoff_counts)\n",
    "    ]\n",
    "    layers = [elem for pair in zip(filters, [Real()] * len(filters)) for elem in pair]\n",
    "    model = nn.Sequential(*layers)\n",
    "    print(model)\n",
    "    print(f\"learning rate: {lr}\")\n",
    "    optim = th.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    initial_loss = mse_loss(noisy_signals, original_signals)\n",
    "    print(f\"Initial loss: {initial_loss.item():.4f}\")\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        optim.zero_grad()\n",
    "        output = mse_loss(model(noisy_signals), original_signals)\n",
    "        if epoch in display_epochs:\n",
    "            print(f\"Epoch {epoch:4d} | Loss {output.item(): >8.4f}\")\n",
    "        if not (trainable_transform or trainable_filter):\n",
    "            break\n",
    "        output.backward()\n",
    "        optim.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = experiment(\n",
    "    gfrft=gfrft,\n",
    "    original_signals=jtv_signal,\n",
    "    initial_orders=[1.0],\n",
    "    cutoff_counts=[10],\n",
    "    noise_sigma=1,\n",
    "    lr=5e-2,\n",
    "    dim=NODE_DIM,\n",
    "    epochs=EPOCHS,\n",
    "    display_epochs=[0, 1, 500, 1000, 1500, 2000],\n",
    "    trainable_transform=True,\n",
    "    trainable_filter=True,\n",
    "    seed=42,\n",
    ")\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
